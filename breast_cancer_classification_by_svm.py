# -*- coding: utf-8 -*-
"""Breast Cancer Classification_by SVM .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11BbswcUv05lxqSXtLoMgaSqXQobQbnoT

##SVM

Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning.

The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.

SVM chooses the extreme points/vectors that help in creating the hyperplane. These extreme cases are called as support vectors, and hence algorithm is termed as Support Vector Machine.

Types of SVM
SVM can be of two types:
Linear SVM: Linear SVM is used for linearly separable data, which means if a dataset can be classified into two classes by using a single straight line, then such data is termed as linearly separable data, and classifier is used called as Linear SVM classifier.
Non-linear SVM: Non-Linear SVM is used for non-linearly separated data, which means if a dataset cannot be classified by using a straight line, then such data is termed as non-linear data and classifier used is called as Non-linear SVM classifier.# Breast Cancer Classification

data sheet collection : Datasets :- https://www.kaggle.com/
objective :- Breast Cancer Classification.

Description:
Breast cancer is the most common cancer amongst women in the world. It accounts for 25% of all cancer cases, and affected over 2.1 Million people in 2015 alone. It starts when cells in the breast begin to grow out of control. These cells usually form tumors that can be seen via X-ray or felt as lumps in the breast area.

The key challenges against itâ€™s detection is how to classify tumors into malignant (cancerous) or benign(non cancerous). We ask you to complete the analysis of classifying these tumors using machine learning (with SVMs) and the Breast Cancer Wisconsin (Diagnostic) Dataset.

Acknowledgements:
This dataset has been referred from Kaggle.

Objective:
Understand the Dataset & cleanup (if required).
Build classification models to predict whether the cancer type is Malignant or Benign.
Also fine-tune the hyperparameters & compare the evaluation metrics of various classification algorithms.
"""

# import all the require library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

# importing the drive
import google_drive_downloader
from google.colab import drive
drive.mount('/content/drive')

#import the data from the drive
data = pd.read_csv("/content/drive/MyDrive/CodeClause Internship /breast-cancer.csv")

"""#Explore the Data:
Explore the data to understand its structure, the available columns, data types, missing values, etc.
"""

data.head()          # Display the first few rows of the data

data.info()   # Get information about the data

data.describe()   # Get summary statistics

print(data.isnull().sum())  # Check for missing values

data.columns #  get the name of all columns present in the columns

data.shape # get the shape of data all columns and rows quantity

data['diagnosis'].value_counts() # the diagnosis columns contain two value  B- benign & m M-malignant

#grouping the benign & malignant
data.groupby('diagnosis').mean()

#seprating the feature and target
x= data.drop(columns='diagnosis',axis =1) # x  contain all the columns except diagnosis
y= data['diagnosis'] # y  contain only diagnosis columns

x # see the x contain

y # see the y contain



# Standardize the features
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)

#split the data in x_train,x_test,y_train,y_test
import sklearn
from sklearn.metrics import accuracy_score
# Now you can use scikit-learn modules and functions
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
x_train,x_test,y_train,y_test = train_test_split(x,y, random_state = 2 , test_size =0.20)

#as we she we train 80% data and test 20% data
print(x.shape,x_train.shape,x_test.shape)

# Create a Logistic Regression model
model = LogisticRegression()

model.fit(x_train,y_train)

#model Evaluation
# Accuracy Score

#Accuracy on Train Data
x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(y_train,x_train_prediction)

print("Accuracy on Training Data (Logistic Regression):", training_data_accuracy)

#Accuracy on Test Data
x_test_prediction = model.predict(x_test)
testing_data_accuracy = accuracy_score(y_test,x_test_prediction)

print("Accuracy on Testing Data (Logistic Regression):", testing_data_accuracy)



"""#SVM"""



# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)

#SVM classifier
svm_classifier = SVC(kernel='linear')  # You can choose the kernel based on your preference

# Train the SVM classifier on the training data
svm_classifier.fit(X_train, y_train)

# Predict using the SVM model
y_pred = svm_classifier.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy using SVM:", accuracy)

"""The accuracy using SVM is increase by 95%"""

import pickle

# Save the SVM model
with open('svm_model.pickle', 'wb') as f:
    pickle.dump(svm_classifier, f)